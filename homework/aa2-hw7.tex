\documentclass[11pt]{article}
\usepackage{master}
\DeclareMathOperator{\diam}{diam}
\newcommand{\interior}[1]{%
  {\kern0pt#1}^{\mathrm{o}}%
}

\let\eps\varepsilon

\title{Accelerated Analysis HW7}
\author{Andrew Hah}
\begin{document}

\pagestyle{plain}
\begin{center}
{\Large MATH 20410. Accelerated Analysis II Homework 7} \\ 
\vspace{.2in}  
Andrew Hah \\
February 28, 2025
\end{center}

\begin{exercise}{6.4}
    \begin{proof} Note that in every subinterval $[x_{i-1}, x_i]$, no matter how small, there are both rational and irrational numbers (both sets are dense in $\mathbb{R}$). Thus,
\[
   M_i \;=\; \sup \{f(x)\colon x \in [x_{i-1}, x_i]\} \;=\; 1,
\]
since there is at least one rational in every interval,
and
\[
   m_i \;=\; \inf \{f(x)\colon x \in [x_{i-1}, x_i]\} \;=\; 0,
\]
since there is at least one irrational in every interval. Therefore, for any partition $P$,
\[
  U(f,P)
  \;=\; \sum_{i=1}^n 1\cdot (x_i - x_{i-1})
  \;=\; b - a,
\]
and
\[
  L(f,P)
  \;=\; \sum_{i=1}^n 0\cdot (x_i - x_{i-1})
  \;=\; 0.
\]
Hence,
\[
  U(f,P) - L(f,P) \;=\; (b - a) - 0
  \;=\; b-a,
\]
which is certainly not $0$ if $b>a$. Because
this difference cannot be made arbitrarily small, $f$ fails the criterion for Riemann integrability, and thus $f$ is not Riemann
integrable on $[a,b]$.
\end{proof}
\end{exercise}

\begin{exercise}{6.10}
\begin{enumerate} [(a)]
    \item \begin{proof}
        Define $F(x) = \frac{x^p}{p} + \frac{v^q}{q} - vx$ for $x \ge 0$. We want to show $F(u) \ge 0$. Let us compute the first and second derivatives of $F$. We have $$F'(x) = x^{p- 1} - v \quad \text{and} \quad F''(x) = (p - 1)x^{p - 2} \ge 0 \quad(x > 0, p \ge1)$$ Since $F''(x) \ge 0$, we see that $F$ is strictly convex. Then, we see that $$F'(x) = 0 \quad \text{when} \quad x = v^{\frac{1}{p-1}}$$ Since $1/p + 1/q = 1 \iff q = \frac{p}{p - 1}$, we get $$x^p = \left( v^{\frac{1}{p - 1}} \right)^p = v^{\frac{p}{p - 1}} = v^q$$ Let $x_0 = v^{\frac{1}{p - 1}}$. Then $$F(x_0) = \frac{x_0^p}{p} + \frac{v^q}{q} - vx_0 = \frac{v^q}{p} + \frac{v^q}{q} - v^q = v^q \left( \frac{1}{p} + \frac{1}{q} - 1 \right) = 0$$ Since $F$ is strictly convex, $x_0$ is its global minimum on $\mathbb{R}_+$ and it is unique. Therefore $F(u) \ge F(x_0) = 0$, which proves $uv \le \frac{u^p}{p} + \frac{v^q}{q}$. Equality holds iff $u^p = v^q$ because $$F(u) = 0 \iff u = x_0 = v^{\frac{1}{p - 1}} \iff u^p = v^q$$
    \end{proof}
    \item \begin{proof}
        We apply part (a) pointwise. For each $x$, we have $$f(x) g(x) \le \frac{f(x)^p}{p} + \frac{g(x)^q}{q}$$ Integrating both sides w.r.t. $\alpha$, we obtain $$\int fg d\alpha \le \int \left( \frac{f(x)^p}{p} + \frac{g(x)^q}{q} \right) d\alpha = \frac{1}{p} \int f^p d\alpha + \frac{1}{q} \int g^q d \alpha = \frac{1}{p} + \frac{1}{q} = 1$$
    \end{proof}
    \item \begin{proof}
        Set $A = \left( \int |f|^p d\alpha \right)^{1/p}$ and $B = \left( \int |g|^q d\alpha \right)^{1/q}$. We define the nonnegative functions $$F(x) = \frac{|f(x)|}{A} \quad \text{and} \quad G(x) = \frac{|g(x)|}{B}$$ Then $$\int F^p d\alpha = \frac{1}{A^p} \int |f|^p d \alpha = 1 \quad \text{and} \quad \int G^q d \alpha = 1$$ From part (b), with $F$ and $G$ in place of $f$ and $g$, we get $$\int FG d \alpha \le 1$$ But $$\int FG d \alpha = \int \frac{|f|}{A} \cdot \frac{|g|}{B} d \alpha = \frac{1}{AB} \int |fg| d \alpha$$ Hence $$\frac{1}{AB} \int |fg| d \alpha \le 1 \implies \int |fg| d \alpha \le AB = \left( \int |f|^p d\alpha \right)^{1/p} \left( \int |g|^q d\alpha \right)^{1/q}$$
    \end{proof}
\end{enumerate}
\end{exercise}

\begin{exercise}{6.11}
    \begin{proof}
        \begin{equation*}
        \begin{split}
            \| f -h \|_2^2 & = \int_a^b |f(x) - h(x)|^2 d \alpha \\
            & = \int_a^b |(f - g)(x) + (g - h)(x)|^2 d \alpha \\
            & = \int_a^b |f - g|^2 + 2(f - g)(g - h) + |g - h|^2 d \alpha \\
            & = \| f - g \|_2^2 + 2 \int_a^b (f - g)(g - h) d \alpha + \| g - h \|_2^2
        \end{split}
    \end{equation*}
    By the Schwarz inequality, the middle term is $$2 \int_a^b (f - g)(g - h) d \alpha \le 2 \| f - g \|_2 \| g - h \|_2$$ Putting these together gives us \begin{equation*}
        \begin{split}
            \| f - h \|_2^2 & \le \| f - g \|_2^2 + 2 \| f - g \|_2 \| g - h \|_2 + \| g - h \|_2^2 \\
            & = (\| f - g\|_2 + \| g - h \|_2)^2
        \end{split}
    \end{equation*}
    Thus taking square roots gives $$\| f - h \|_2 \le \| f - g \|_2 + \| g- h\|_2$$
    \end{proof}
\end{exercise}

\begin{exercise}{6.12}
    \begin{proof}
        Define as in the hint, $$g(t) = \frac{x_i - t}{\Delta x_i} f(x_{i -1}) + \frac{t - x_{i - 1}}{\Delta x_i} f(x_i)$$ On each subinterval $[x_{i - 1}, x_i]$, $g \le \max \{ f(x_{i - 1}), f(x_i) \}$.  For any $t \in [x_{i - 1}, x_i]$, $$|f(t) - g(t)| \le |f(t) - f(x_{i - 1})| + |f(x_{i - 1}) - g(t)|$$ We see that the second term is at most $|f(x_{i - 1}) - f(x_i)|$ (given the range of $g$), hence $$|f(t) - g(t)| \le |f(t) - f(x_{i - 1})| + |f(x_i) - f(x_{i - 1})|$$ Because $f \in \mathcal{R}(\alpha)$, $f$ is bounded. Concretely, given $\delta > 0$, we can choose a partition $P$ of $[a, b]$ such that on each subinterval $[x_{i - 1}, x_i]$, $\sup\{ |f(u) - f(v)|: u, v \in [x_{i - 1}, x_i] \} < \delta$. Then for every $t \in [x_{i - 1}, x_i]$ we get $$|f(t) - g(t)| \le |f(t) - f(x_{i - 1})| + |f(x_{i - 1}) - f(x_i)| \le 2 \delta$$ Now we estimate $\| f - g \|_2^2 = \int_a^b |f - g|^2 d \alpha$. \begin{equation*}
            \begin{split}
                \int_a^b |f(t) - g(t)|^2 d \alpha & = \sum_{i = 1}^r \int_{x_{i - 1}}^{x_i} |f(t) - g(t)|^2 d \alpha \\
                & \le 4 \delta^2  \sum_{i = 1}^r (\alpha(x_i) - \alpha(x_{i - 1})) \\
                & = 4 \delta^2 (\alpha(b) - \alpha(a))
            \end{split}
        \end{equation*}
        Let $M = \alpha(b) - \alpha(a)$. If we want $\| f - g\|_2 < \eps$, it suffices to have $$\| f - g \|_2^2 = \int_a^b |f - g|^2 d \alpha < \eps^2$$ From the above inequality, we have $$\| f - g\|_2^2 \le 4 \delta^2 M$$ so we can guarantee $\| f - g\|_2^2 < \eps^2$ by choosing $$4\delta^2 M < \eps \iff \delta <\frac{\eps}{2 \sqrt{M}}$$
    \end{proof}
\end{exercise}

\begin{exercise}{6.15}
    \begin{proof}
        \begin{enumerate} [(i)]
            \item We first note that $$\frac{d}{dx} (f(x)^2) = 2 f(x) f'(x)$$ Hence $$xf(x)f'(x) = \frac{1}{2} \frac{d}{dx} (f(x)^2)$$ We now move to integrating what we are interested in. \begin{equation*}
            \begin{split}
                \int_a^b x f(x) f'(x) dx & = \frac{1}{2} \int_a^b x (f(x)^2)' dx
            \end{split}
        \end{equation*}
        Now we integrate by parts, taking $u = x$ and $dv = (f(x)^2)' dx$. The boundary term is $$xf(x)^2 \mid_{a}^b = bf(b)^2 - af(a)^2 = 0$$ Hence $$\int_a^b x(f(x)^2)'dx = - \int_a^b f(x)^2 dx$$ But by hypothesis, this is equal to $-1$, so putting this all together gives $$\int_a^b x f(x) f'(x) dx = -\frac{1}{2}$$
        \item Applying the Schwarz inequality, we get $$\left( \int_a^b xf(x) f'(x) dx \right)^2 \le \left( \int_a^b x^2 f(x)^2 dx \right) \left( \int_a^b (f'(x))^2 dx \right)$$ Since we have already shown above that $\int x f f' = -1/2$, the left hand side is $1/4$, i.e. $$\frac{1}{4} \le \left( \int_a^b x^2 f(x)^2 dx \right) \left( \int_a^b (f'(x))^2 dx \right)$$ We can actually make this inequality strict because equality would suggest that $xf(x)$ is a constant multiple of $f'(x)$ almost everywhere, but since $f(a) = f(b) = 0$, this would mean $f \equiv 0$ which is contradicted by the fact that $\int f^2 = 1$. Thus, we have $$\left( \int_a^b x^2 f(x)^2 dx \right) \left( \int_a^b (f'(x))^2 dx \right) > \frac{1}{4}$$
        \end{enumerate}
    \end{proof}
\end{exercise}

\begin{exercise}{7.1}
    \begin{proof}
        By uniform convergence, we have that $\forall \eps > 0$, $\exists N$ such that if $n \ge N$, then $|f_n(x) - f(x)| < \eps$, i.e. $\displaystyle \sup_x |f_n(x) - f(x) | < \eps$. Since each $f_n$ is bounded, so is $f$. Let $$\displaystyle M = \sup_x |f(x)| < \infty$$. For $n \ge N$, we get $$\sup_x |f_n(x)| \le \sup_x |f_n(x) - f(x)| + \sup_x |f(x)| \le \eps + M$$ For the finitely many indices $n < N$, each $f_n$ is still bounded, so let $$M_0 = \max\{ \sup_x |f_1(x)|, \dots, \sup_x |f_{N - 1}(x)| \}$$ Finally, if we choose $B = \max\{ M_0, M + \eps \}$, then we have that $\sup_x |f_n(x)| \le B$ for all $n$, thus $\{ f_n \}$ is uniformly bounded. 
    \end{proof}
\end{exercise}

\begin{exercise}{7.8}
    \begin{proof}
        For each $n$, $I(x - x_n)$ is either 0 or 1, so $$|c_nI(x - x_n)| \le |c_n|$$ Since $\sum_1^\infty |c_n|$ converges, we can denote $M = \sum_{i = 1}^\infty |c_n|$, which then means that the partial sums $\sum_{n = 1}^N |c_n|$ are uniformly bounded by $M$. We can apply the Weierstrass $M$ test, which gives us that $\sum_{n = 1}^\infty c_n I(x - x_n)$ converges uniformly on $[a, b]$. To prove continuity $\forall x \neq x_n$, we fix some $x_0 \in [a, b]$ such that $x_0 \neq x_n$ for all $n$. Then there is a small interval $(x_0 - \delta, x_0 + \delta)$ around $x_0$ that does not contain any $x_n$. For each $n$, the value of $I(x - x_n)$ is constant for $x \in (x_0 - \delta, x_0 + \delta)$. Thus the partial sum $S_N(x) = \sum_{n = 1}^N c_n I(x - x_n)$ is also constant in that neighborhood of $x_0$, so $S_N$ is continuous at $x_0$. We know that $S_N \to f$ uniformly, and a uniform limit of continuous functions is continuous, which gives us that $f$ is continuous at $x_0$. 
    \end{proof}
\end{exercise}

\begin{exercise}{1}
    \begin{proof}
        We know from a previous theorem that if $f$ is monotonic (and bounded) on $[a, b]$ and if $\alpha$ is continuous (and monotonic) on $[a, b]$, then $f \in \mathcal{R}(\alpha)$. In this case we see that $\alpha$ is monotonic (-ally increasing) on $[a, b]$ and continuous, so we get for free that $\alpha \in \mathcal{R}(\alpha)$. We use integration by parts on $f = g = \alpha$. Then $$\int_a^b \alpha d \alpha = \alpha(b)\alpha(b) - \alpha(a) \alpha(a) - \int_a^b \alpha d\alpha$$ Rearranging, we get $2 \int_a^b \alpha d\alpha = \alpha(b)^2 - \alpha(a)^2$ so $$\int_a^b \alpha d \alpha = \frac{1}{2} (\alpha(b)^2 - \alpha(a)^2)$$
    \end{proof}
\end{exercise}

\end{document}