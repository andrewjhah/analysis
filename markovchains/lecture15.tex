\documentclass[11pt]{article}
\usepackage{master}
\title{Markov Chains Lec 15}
\author{Andrew Hah}

\begin{document}

\pagestyle{plain}
\begin{center}
{\Large MATH 23500} \\
{\Large Lecture 15} \\
\vspace{.2in}
April 28, 2025
\end{center}

Suppose $X$ and $Y$ take values in countable sets $S, T \subset \bbR$. For $x \in S, y \in T$, let $$f(x, y) = \bbP \{ X = x, Y= y \}$$ Then $$\displaystyle \bbE [ X \mid Y= y] = \sum_{x \in S} x \bbP \{ X = x \mid Y= y \} = \frac{\sum_{x \in S} x f(x, y)}{\sum_{x \in S}f(x, y)}$$ We define the random variable $$\bbE [ X \mid Y ] = \frac{\sum_{x \in S} x f(x, Y)}{\sum_{x \in S}f(x, Y)}$$

\begin{definition}
  Let $X, Y$ be random variables with $X$ taking values in $\bbR$, and $\bbE [ |X| ] < \infty$. The \emph{conditional expectation} $\bbE [ X \mid Y]$ is the unique random variable satisfying the following \begin{enumerate}
  \item $\bbE [X \mid Y]$ is a function of $Y$.
  \item If $F(Y)$ is a function of $Y$ with $\bbE [|F(Y)|] < \infty$, then $$\bbE [X F(Y)] = \bbE [ \bbE [ X \mid Y ] F(Y)]$$
  \end{enumerate}
\end{definition}

We typically consider a sequence $\{ Y_n \}_{n \ge 0}$ of random variables and condition on $Y_0, Y_1, \dots, Y_n$ for some $n$.

\begin{definition} We write $\mathcal{F}_n$ for the information contained in $Y_0, \dots, Y_n$, i.e., $\mathcal{F}_n$ is the smallest $\sigma$-algebra generated by $Y_0, \dots, Y_n$. Thus, $$\bbE [X \mid \mathcal{F}_n] = \bbE [X \mid Y_0, \dots, Y_n ], \quad \forall \text{r.v.'s } X $$ We say that $X$ is $\mathcal{F}_n$-measurable if it is a function of $Y_0, \dots, Y_n$. 
\end{definition}

\begin{proposition} $\bbE [ X \mid \mathcal{F}_n ]$ is the unique random variable satisfying the following \begin{enumerate}
  \item $\bbE [X \mid \mathcal{F}_n]$ is $\mathcal{F}_n$-measurable.
  \item If $Z$ is $\mathcal{F}_n$-measurable, then $\bbE [XZ] = \bbE[\bbE[ X \mid \mathcal{F}_n] Z]$.
  \end{enumerate}
\end{proposition}

\begin{proposition} If $X_1, X_2$ are real-valued random variables and $a, b \in \bbR$ are non-random, then $$\bbE [ aX_1 + bX_2 \mid \mathcal{F}_n] = a \bbE [X_1 \mid \mathcal{F}_n] + b \bbE [ X_2 \mid \mathcal{F}_n]$$
\end{proposition}
\begin{proof}
  Suppose $Z$ is $\mathcal{F}_n$-measurable. $$\bbE[ \bbE [ a X_1 + bX_2 \mid \mathcal{F}_n]Z] = \bbE [(aX_1 + bX_2)Z]$$ Also, \begin{align*} \bbE [ ( \bbE [ X_1 \mid \mathcal{F}_n] + b \bbE [X_{2} \mid \mathcal{F}_n]) Z] &  = a \bbE [ \bbE [X_1 \mid \mathcal{F}_n] Z] + b \bbE [ \bbE [X_2 \mid \mathcal{F}_n]Z] \\ & = a \bbE [X_1Z] + b\bbE [X_2Z] \\ & = \bbE [(aX_1 + bX_2) Z] \end{align*}
\end{proof}

\begin{proposition} Suppose $X$ is $\mathcal{F}_n$-measurable. Then $$\bbE[ X \mid \mathcal{F}_n] =  X$$
\end{proposition}

\begin{proposition} Suppose $X$ is independent of $\mathcal{F}_n$. Then $$\bbE [ X \mid \mathcal{F}_n] = \bbE [ X]$$
\end{proposition}

\begin{example} Suppose $X_1, X_2, \dots$ are i.i.d. with mean $\mu$. Let $\mathcal{F}_n$ be the information contained in $X_1, \dots, X_n$. Find $$\bbE[ X_1 + \dots + X_n \mid \mathcal{F}_m]$$
  If $m \ge n$, $$\bbE[ X_1 + \dots + X_n \mid \mathcal{F}_m] = X_1 + \dots + X_n$$
  If $m < n$, \begin{align*} \bbE[ X_1 + \dots + X_n \mid \mathcal{F}_m] & = \bbE [ X_1 + \dots + X_m \mid \mathcal{F}_m] + \bbE [ X_{m + 1} + \dots + X_n \mid \mathcal{F}_m] \\ & = X_1 + \dots + X_m + (n -m)\mu \end{align*}
\end{example}

\begin{example} Suppose $X_1, X_2, \dots$ are i.i.d. with mean $0$, variance $\sigma ^2$. Let $\mathcal{F}_n$ be the information contained in $X_1, \dots, X_n$. Find $$\bbE [(X_1 + \dots + X_n)^2 \mid \mathcal{F}_m]$$
  Let $S_n = X_1 + \dots X_n$. Then $$S_n^2 = (S_m + (S_n - S_m))^2 = S_m^2 + (S_n - S_m)^2 + 2S_m(S_n - S_m)$$ Thus, \begin{align*} \bbE[ S_n^2 \mid \mathcal{F}_m] & = \bbE [ S_m^2 \mid \mathcal{F}_m] + \bbE [ (S_n - S_m)^2 \mid \mathcal{F}_m] + \bbE[ 2 S_m(S_n - S_m) \mid \mathcal{F}_m] \\ & = S_m^2 + (n - m)\sigma^2 \end{align*}
\end{example}

\end{document}
